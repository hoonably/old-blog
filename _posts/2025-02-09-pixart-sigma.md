---
layout: blog
title: "PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation"
subtitle: ""
date: 2025-02-09 21:52:24 +09:00
categories: paper
author: "hoonably"
---
<div class="page-body"><table id="198451cf-7b79-805f-bd44-e09e7b51e51b" class="simple-table"><tbody><tr id="198451cf-7b79-803e-8cf3-c2ed86d84ade"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">ArXiv</th><td id="L|H:" class="" style="width:580.5px"><a href="https://arxiv.org/abs/2403.04692">https://arxiv.org/abs/2403.04692</a></td></tr><tr id="198451cf-7b79-80eb-8b93-f3080c4fd2b0"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Project Page</th><td id="L|H:" class="" style="width:580.5px"><a href="https://pixart-alpha.github.io/PixArt-sigma-project/">https://pixart-alpha.github.io/PixArt-sigma-project/</a></td></tr><tr id="198451cf-7b79-80aa-8b1c-fc11c387db38"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Github Code</th><td id="L|H:" class="" style="width:580.5px"><a href="https://github.com/PixArt-alpha/PixArt-sigma">https://github.com/PixArt-alpha/PixArt-sigma</a></td></tr></tbody></table><figure id="1b7451cf-7b79-8031-b1e6-f4bb1b665391"><div class="source"><a href="/images/2025-02-09-pixart-sigma/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pptx">250213_JeonghoonPark_PixArt-Σ_ Weak-to-Strong_Training.pptx</a></div></figure><figure id="1b7451cf-7b79-800b-ad90-f1b6c78892ef"><div class="source"><a href="/images/2025-02-09-pixart-sigma/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pdf">250213_JeonghoonPark_PixArt-Σ_ Weak-to-Strong_Training.pdf</a></div></figure><p id="198451cf-7b79-80d2-b472-d6b4113fd4ef" class="">
</p><p id="198451cf-7b79-80ef-b602-eaf56ceb467d" class=""><a href="https://www.notion.so/PixArt-Fast-Training-of-Diffusion-Transformer-for-Photorealistic-Text-to-Image-Synthesis-198451cf7b798018891cfb85e1cd3523?pvs=21">PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis</a> </p><p id="198451cf-7b79-806a-8e48-e2bcdb0e8562" class="">
</p><p id="198451cf-7b79-8062-a5ff-ef73c84b831b" class="">
</p><figure class="block-color-teal_background callout" style="white-space:pre-wrap;display:flex" id="198451cf-7b79-8031-9793-d00fb2183a11"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><p id="198451cf-7b79-807c-9b53-ed6cb2a89a3c" class="">Key Differentiator</p><ul id="198451cf-7b79-807d-8217-e96243306ed6" class="bulleted-list"><li style="list-style-type:disc">기존 연구였던 PixArt-α에서 최적화를 통해 4K 초고해상도까지 가능하도록 연구</li></ul><ul id="198451cf-7b79-8044-b111-eca8efac0fdb" class="bulleted-list"><li style="list-style-type:disc">4K를 transformer를 활용해 directly로 한번에 생성</li></ul></div></figure><p id="198451cf-7b79-80dd-a527-d58350acefed" class="">
</p><h1 id="198451cf-7b79-8054-9266-dd0fbbab0df3" class="">2. Related Work</h1><h3 id="198451cf-7b79-80e7-8cdf-c20770f56386" class="">1️⃣ PixArt-α (ICLR 2024 Spotlight) </h3><ul id="198451cf-7b79-8039-93ab-cb67747cd116" class="bulleted-list"><li style="list-style-type:disc">최초의 Transformer 기반 Diffusion Model (DiT)로 1024×1024 해상도까지 생성 가능</li></ul><h3 id="198451cf-7b79-803d-aa36-d7a69c28e183" class="">2️⃣ Stable Diffusion XL (SDXL, 2023)</h3><ul id="198451cf-7b79-802f-ab00-d37289afc27a" class="bulleted-list"><li style="list-style-type:disc">Latent Diffusion Model (LDM) 구조를 활용하여 1024×1024 이상의 고해상도 이미지 생성 가능</li></ul><h3 id="198451cf-7b79-80ab-9702-cb59f71cd9e5" class="">3️⃣ GigaGAN (Adobe, 2023)</h3><ul id="198451cf-7b79-80e2-b084-d12dc0459490" class="bulleted-list"><li style="list-style-type:disc">GAN 기반 초고해상도 이미지 생성 모델 (1024px 이상 지원)</li></ul><h3 id="198451cf-7b79-80a8-868a-db925c0f61f7" class="">4️⃣ LLaVA (Visual Instruction Tuning, 2023) </h3><ul id="198451cf-7b79-8032-8076-f4fa005acb4e" class="bulleted-list"><li style="list-style-type:disc">이미지-텍스트 정렬을 학습하여 이미지에 대한 설명(캡션)을 자동으로 생성하는 모델</li></ul><h3 id="198451cf-7b79-80f9-8912-c30f3ce54c23" class="">5️⃣ DALL·E 3 (OpenAI, 2023)</h3><ul id="198451cf-7b79-805d-b950-e46e7b89aa1a" class="bulleted-list"><li style="list-style-type:disc">GPT-4 기반 텍스트 이해력을 활용하여 프롬프트를 더 정밀하게 반영</li></ul><p id="198451cf-7b79-8005-83d0-f4946cd8ffde" class="">
</p><p id="198451cf-7b79-8009-b0be-d2add40b8edc" class="">
</p><h1 id="198451cf-7b79-803f-91bc-fe73edcc8649" class="">3. Framework</h1><h2 id="198451cf-7b79-802c-aba9-d4325efaeb2a" class="">3.1 Data Analysis</h2><table id="198451cf-7b79-806a-b5fd-ccf03e0bc696" class="simple-table"><tbody><tr id="198451cf-7b79-8035-93a0-da8afe5819bc"><td id="FloJ" class="" style="width:230px"></td><td id="RKqt" class="" style="width:230px">Data</td><td id="}{dw" class="" style="width:230px"></td></tr><tr id="198451cf-7b79-803d-af4d-d1501fec2a76"><td id="FloJ" class="" style="width:230px">Internal-α</td><td id="RKqt" class="" style="width:230px">14M</td><td id="}{dw" class="" style="width:230px"></td></tr><tr id="198451cf-7b79-80ee-af10-f8e54e7ee345"><td id="FloJ" class="" style="width:230px">Internal-Σ</td><td id="RKqt" class="" style="width:230px">33M</td><td id="}{dw" class="" style="width:230px">&gt;=1K (33M)<br/>real photo 4K (8M)<br/></td></tr><tr id="198451cf-7b79-80c3-8e22-d316a427fc0d"><td id="FloJ" class="" style="width:230px">SD v1.5<br/>(open-source)<br/></td><td id="RKqt" class="" style="width:230px">2B</td><td id="}{dw" class="" style="width:230px"></td></tr></tbody></table><p id="198451cf-7b79-8094-a271-f15fe615d403" class="">a 때보다 데이터가 많이 늘었고, 4K real photo도 추가함.</p><p id="198451cf-7b79-804e-a0e8-ea8d09177909" class="">하지만 SD v1.5가 2B 데이터인걸 감안하면 아주 제한적인 데이터.</p><p id="198451cf-7b79-8047-a9b8-d44900df2519" class="">하지만 효과적으로 training함.</p><p id="198451cf-7b79-808f-bfc7-fc83e49af522" class="">이미지의 예술적 품질을 평가하는 Aesthetic Scoring Model(AES)을 사용하여 2M(200만 장)의 고품질 이미지 선별.</p><p id="198451cf-7b79-8080-9945-d495868ec074" class=""> → 해상도가 높아질수록 모델의 충실도(프레셰 초점 거리(FID) [18])와 의미적 정렬(CLIP 점수)이 향상</p><p id="198451cf-7b79-80dd-93c1-eaeba7f736e3" class="">
</p><h3 id="198451cf-7b79-80c0-b8ba-d7a58115cbd8" class="">Better Text-Image Alignment</h3><p id="198451cf-7b79-80ae-965a-ec87b601306a" class="">➡ 텍스트 프롬프트(설명)와 생성된 이미지가 얼마나 일치하는지</p><p id="198451cf-7b79-80f7-9a72-eedfecb581fe" class="">즉, 사용자가 입력한 텍스트(prompt)와 모델이 생성한 이미지가 얼마나 정확하게 대응하는지를 평가하는 개념</p><hr id="198451cf-7b79-801c-a94a-e793a150eaf7"/><p id="198451cf-7b79-800b-943b-f61d0b223d53" class="">
</p><p id="198451cf-7b79-8096-84b6-d5cdcd2f5df3" class="">PixArt-α 는 LLaVa를 사용하였고, PixArt-Σ는 Share-Captioner 사용</p><table id="198451cf-7b79-80d5-be53-ec995af83c2a" class="simple-table"><tbody><tr id="198451cf-7b79-8006-b421-c92e94756f9c"><td id="Nq=E" class="">항목</td><td id="&gt;m?`" class="">LLaVA</td><td id="URoO" class="">Share-Captioner</td></tr><tr id="198451cf-7b79-80e9-bf0a-d06eba170da4"><td id="Nq=E" class="">기반 모델</td><td id="&gt;m?`" class="">CLIP + LLaMA</td><td id="URoO" class="">GPT-4V (GPT-4 with Vision)</td></tr><tr id="198451cf-7b79-804b-ba84-e90260dc87ed"><td id="Nq=E" class="">텍스트 생성</td><td id="&gt;m?`" class="">비교적 단순</td><td id="URoO" class="">더 길고 세밀한 설명</td></tr><tr id="198451cf-7b79-800d-be93-f670c3a83f1f"><td id="Nq=E" class="">정확도</td><td id="&gt;m?`" class="">가끔 환각 문제 발생</td><td id="URoO" class="">더 높은 정확도</td></tr><tr id="198451cf-7b79-80ea-b426-f684de0c5237"><td id="Nq=E" class="">이미지 디테일 반영</td><td id="&gt;m?`" class="">제한적 (단순 설명)</td><td id="URoO" class="">더 정밀한 객체 및 관계 설명</td></tr><tr id="198451cf-7b79-80c3-85ac-e5d3a5db0589"><td id="Nq=E" class="">캡션 품질</td><td id="&gt;m?`" class="">일반적인 설명 수준</td><td id="URoO" class="">고품질, 구체적인 묘사 가능</td></tr></tbody></table><p id="198451cf-7b79-8054-b0bf-d21d70addb5a" class="">다음과 같은 환각 (Hallucinations)가 발생했었음</p><figure id="198451cf-7b79-8065-861b-c4b5ec4453e4" class="image"><a href="/images/2025-02-09-pixart-sigma/image.png"><img style="width:710px" src="/images/2025-02-09-pixart-sigma/image.png"/></a></figure><table id="198451cf-7b79-80f3-978e-cf487938785a" class="simple-table"><tbody><tr id="198451cf-7b79-8013-b727-c467469468e9"><td id="k:ap" class="">항목</td><td id="dz&gt;|" class="">PixArt-α</td><td id="OS[X" class="">PixArt-Σ</td></tr><tr id="198451cf-7b79-80e9-bc66-c227557f3ed0"><td id="k:ap" class="">텍스트 해석 길이</td><td id="dz&gt;|" class="">120 토큰</td><td id="OS[X" class="">300 토큰 (2.5배 증가)</td></tr><tr id="198451cf-7b79-8041-9e0a-c4af31775aaa"><td id="k:ap" class="">캡션 생성 모델</td><td id="dz&gt;|" class="">LLaVA (단순함)</td><td id="OS[X" class="">Share-Captioner (정확한 설명)</td></tr><tr id="198451cf-7b79-8046-9264-eaa64c9255c9"><td id="k:ap" class="">CLIP Score</td><td id="dz&gt;|" class="">0.2787</td><td id="OS[X" class="">0.2797 (향상됨)</td></tr><tr id="198451cf-7b79-808c-913b-d00e8ef74ed4"><td id="k:ap" class="">환각 문제 해결</td><td id="dz&gt;|" class="">일부 존재</td><td id="OS[X" class="">환각 감소 (더 정밀한 캡션 사용)</td></tr></tbody></table><p id="198451cf-7b79-80e2-a725-d5aaa614509c" class="">➡ PixArt-Σ는 더 긴 문장을 해석하고, 더 정교한 캡션을 사용하여 텍스트-이미지 정렬 성능을 높였음.</p><p id="198451cf-7b79-80f6-826c-e0f1bc0b8c01" class="">➡ Share-Captioner를 사용하여 텍스트와 이미지 간 정보 일치도를 개선함.</p><p id="198451cf-7b79-8025-9e40-fd291a222d6b" class="">
</p><h3 id="198451cf-7b79-808e-be20-f1c17483c338" class="">평가 데이터셋 구성 (High-Quality Evaluation Dataset)</h3><ul id="198451cf-7b79-803b-a1ce-c3608601a4dd" class="bulleted-list"><li style="list-style-type:disc">기존 모델들이 사용하는 MSCOCO 데이터셋은 예술적 품질과 텍스트-이미지 정렬을 평가하기에 충분하지 않음.</li></ul><ul id="198451cf-7b79-8045-ae4f-efb63a2d748a" class="bulleted-list"><li style="list-style-type:disc">따라서 PixArt-Σ는 새로운 평가 데이터셋(30,000개 샘플) 구축.</li></ul><ul id="198451cf-7b79-803f-a441-dc2aa675503c" class="bulleted-list"><li style="list-style-type:disc">평가 항목:<ol type="1" id="198451cf-7b79-8003-89f5-c0abf99ff796" class="numbered-list" start="1"><li>Fréchet Inception Distance (FID) → 이미지 품질 평가</li></ol><ol type="1" id="198451cf-7b79-80a2-b92d-e8a45717310e" class="numbered-list" start="2"><li>CLIP Score → 텍스트-이미지 정렬 성능 평가</li></ol></li></ul><figure id="198451cf-7b79-8081-a740-d196f7dc6842" class="image"><a href="/images/2025-02-09-pixart-sigma/image%201.png"><img style="width:709.9921875px" src="/images/2025-02-09-pixart-sigma/image%201.png"/></a></figure><p id="198451cf-7b79-80c0-b162-f80a0b19ea6d" class="">
</p><h2 id="198451cf-7b79-80b8-ae3c-d5fcacbb1181" class="">3.2 Efficient DiT Design</h2><h3 id="198451cf-7b79-80e2-8888-c17a52a8ee63" class="">Key-Value (KV) Token Compression 기법</h3><p id="198451cf-7b79-8049-9263-f5e57018fa91" class="">🔹 기존 Attention 연산 문제</p><ul id="198451cf-7b79-8027-b657-ea8f7f53bf6a" class="bulleted-list"><li style="list-style-type:disc">Self-Attention은 Query(Q), Key(K), Value(V)의 곱을 계산하는 방식이므로,토큰 개수가 많아질수록 연산량이 O(N²)으로 증가함.</li></ul><ul id="198451cf-7b79-802f-8e55-fb70012806b9" class="bulleted-list"><li style="list-style-type:disc">해결 방법: Key와 Value 토큰을 압축하여 연산량을 줄임.</li></ul><p id="198451cf-7b79-80c4-b162-ebc204c2c617" class="">🔹 PixArt-Σ의 KV Token Compression 방식</p><figure id="198451cf-7b79-8088-be83-fafd7b67dbfb" class="image"><a href="/images/2025-02-09-pixart-sigma/image%202.png"><img style="width:709.96875px" src="/images/2025-02-09-pixart-sigma/image%202.png"/></a></figure><ul id="198451cf-7b79-8055-b065-e62734c337f6" class="bulleted-list"><li style="list-style-type:disc">PixArt-Σ (토큰 압축 적용):<ul id="198451cf-7b79-80e6-9918-f8479cc458e0" class="bulleted-list"><li style="list-style-type:circle">Key(K)와 Value(V)를 Stride 2의 Group Convolution을 사용해 압축</li></ul><ul id="198451cf-7b79-8060-b36a-c9a6a17dd65b" class="bulleted-list"><li style="list-style-type:circle">이를 통해 토큰 개수를 N → N/R^2 으로 줄임</li></ul><ul id="198451cf-7b79-801c-a1ae-f1c8f24b4892" class="bulleted-list"><li style="list-style-type:circle">정확도가 크게 떨어지지 않는 선에서 R을 조정 (1~4)하기</li></ul><ul id="198451cf-7b79-809f-9846-c8c4c821cbc6" class="bulleted-list"><li style="list-style-type:circle">최종적으로 연산량을 기존 대비 약 34% 절감</li></ul></li></ul><p id="198451cf-7b79-8049-9ab7-f2a09ab8e72c" class="">✅ 핵심 효과</p><ul id="198451cf-7b79-8056-9eaf-dd82c453c628" class="bulleted-list"><li style="list-style-type:disc">4K 해상도 이미지 생성 속도 향상 (연산량 감소)</li></ul><ul id="198451cf-7b79-801f-a25a-ed00880f1261" class="bulleted-list"><li style="list-style-type:disc">메모리 사용량 감소 → 더 작은 GPU에서도 실행 가능</li></ul><ul id="198451cf-7b79-80f0-bd60-d48a4927c35c" class="bulleted-list"><li style="list-style-type:disc">기존 PixArt-α 모델에서 자연스럽게 업그레이드 가능 (기존 모델의 가중치를 활용)</li></ul><p id="198451cf-7b79-80d8-8f6b-d3d2449972f5" class="">
</p><div id="198451cf-7b79-809a-ac9f-d17f72b6045b" class="column-list"><div id="198451cf-7b79-8071-9b2c-c5a415a72560" style="width:31.25%" class="column"><figure id="198451cf-7b79-8086-824b-e53cc50346f3" class="image"><a href="/images/2025-02-09-pixart-sigma/image%203.png"><img style="width:384px" src="/images/2025-02-09-pixart-sigma/image%203.png"/></a></figure></div><div id="198451cf-7b79-8081-ab48-dd6e6c89f2de" style="width:68.75%" class="column"><figure id="198451cf-7b79-8021-88a9-e77e27d26536" class="image"><a href="/images/2025-02-09-pixart-sigma/image%204.png"><img style="width:414.984375px" src="/images/2025-02-09-pixart-sigma/image%204.png"/></a></figure></div></div><p id="198451cf-7b79-80b5-9ee9-ed637f7cb885" class="">
</p><h2 id="198451cf-7b79-809c-b328-de46d4823a87" class=""><mark class="highlight-red_background">3.3 Weak-to-Strong Training Strategy</mark></h2><p id="198451cf-7b79-808a-acef-c10179883a61" class="">PixArt-Σ의 Weak-to-Strong Training은 기존 모델의 가중치를 활용하여 빠르게 적응하도록 설계됨.</p><p id="198451cf-7b79-80c3-9764-c9e7f02bbfe9" class="">이 과정에서 3단계의 학습 전략이 적용됨.</p><h3 id="198451cf-7b79-8065-9a2f-eeba0942ed68" class="">(1) VAE 적응 (VAE Adaptation)</h3><ul id="198451cf-7b79-800d-961e-e6ac5d1ad031" class="bulleted-list"><li style="list-style-type:disc">PixArt-α에서 사용하던 기존 VAE를 Stable Diffusion XL(SDXL)의 VAE로 교체</li></ul><ul id="198451cf-7b79-8071-a78b-fc9b003b5144" class="bulleted-list"><li style="list-style-type:disc">VAE 교체 후 빠른 적응을 위해 2K Training Steps 만에 수렴하도록 학습 전략 적용.</li></ul><ul id="198451cf-7b79-8053-a90a-cfaa0ba38d98" class="bulleted-list"><li style="list-style-type:disc">새로운 VAE 적용 후에도 기존 모델의 가중치를 재사용하여 빠르게 학습 가능.</li></ul><figure id="198451cf-7b79-80fd-9882-fd418e35e033" class="image"><a href="/images/2025-02-09-pixart-sigma/image%205.png"><img style="width:192px" src="/images/2025-02-09-pixart-sigma/image%205.png"/></a></figure><h3 id="198451cf-7b79-8089-ab89-e83180516114" class="">(2) 해상도 업그레이드 (Resolution Upscaling)</h3><ul id="198451cf-7b79-8034-b4d7-e760cce21a49" class="bulleted-list"><li style="list-style-type:disc">256px → 512px → 1024px → 4K로 점진적으로 해상도를 증가시키며 학습.</li></ul><p id="198451cf-7b79-8041-8bb3-c3d39baceb06" class="">
</p><ul id="198451cf-7b79-80dc-b383-d42b890aad81" class="bulleted-list"><li style="list-style-type:disc">PE Interpolation(위치 임베딩 보간법)을 적용하여, 기존 해상도의 가중치를 새 해상도에서도 자연스럽게 사용 가능하도록 조정.<ul id="198451cf-7b79-8016-8b64-ebffce1c0a0e" class="bulleted-list"><li style="list-style-type:circle">보간법 (Interpolation)은 알려진 값을 기반으로 값을 계산하는 프로세스</li></ul><ul id="198451cf-7b79-80eb-a35f-cc4f2889d425" class="bulleted-list"><li style="list-style-type:circle">Transformer 기반 모델(예: DiT, ViT 등)은 입력 이미지의 각 위치 정보를 표현하기 위해 위치 임베딩을 사용.</li></ul><ul id="198451cf-7b79-804e-a70b-dfe7ed7acf2c" class="bulleted-list"><li style="list-style-type:circle">모델이 256×256에서 학습되었다면, 256×256 해상도에 최적화된 위치 임베딩을 학습함.</li></ul><ul id="198451cf-7b79-8079-9c34-e54a8e55ab66" class="bulleted-list"><li style="list-style-type:circle">하지만 해상도를 1024×1024로 증가시키면, 기존 256×256 위치 임베딩과 구조가 달라져 모델 성능이 급격히 저하됨.</li></ul><ul id="198451cf-7b79-80f8-9048-c73c948bdbcb" class="bulleted-list"><li style="list-style-type:circle">기존 위치 임베딩을 1024×1024 크기로 보간(interpolation)</li></ul><ul id="198451cf-7b79-8043-b3b4-e2920a91b91b" class="bulleted-list"><li style="list-style-type:circle">즉, 256개의 값을 1024개로 확장하는 과정에서 자연스럽게 매끄러운 값으로 변환됨.</li></ul><ul id="198451cf-7b79-8013-9876-f3670f97cbf6" class="bulleted-list"><li style="list-style-type:circle">이를 통해 새로운 해상도에서도 기존 모델의 공간 정보가 유지됨.</li></ul></li></ul><p id="198451cf-7b79-80f3-8aec-ce3be5a8bf54" class="">
</p><ul id="198451cf-7b79-802a-856f-f36bc35a2370" class="bulleted-list"><li style="list-style-type:disc">단 1000 Training Steps만으로도 해상도 증가에 적응 가능.</li></ul><figure id="198451cf-7b79-8079-b2a7-f961c1a116f2" class="image"><a href="/images/2025-02-09-pixart-sigma/image%206.png"><img style="width:336px" src="/images/2025-02-09-pixart-sigma/image%206.png"/></a></figure><h3 id="198451cf-7b79-8021-804d-dbb1290586b1" class="">(3) KV Token Compression 도입 (연산 최적화)</h3><ul id="198451cf-7b79-80c3-9ef1-cd43af5a1f54" class="bulleted-list"><li style="list-style-type:disc">PixArt-Σ 모델은 KV Token Compression을 적용했음</li></ul><ul id="198451cf-7b79-80d7-b51e-ee970b3f868e" class="bulleted-list"><li style="list-style-type:disc"><span style="border-bottom:0.05em solid">하지만 </span><span style="border-bottom:0.05em solid">기존 모델과 구조가 달라서 성능 저하 위험이 있음</span><span style="border-bottom:0.05em solid">.</span></li></ul><ul id="198451cf-7b79-8090-b867-fb9a897b201f" class="bulleted-list"><li style="list-style-type:disc">PixArt-Σ에서는 기존 모델에서 자연스럽게 적응하도록 &quot;Conv Avg Init.&quot; 전략 적용.</li></ul><h3 id="198451cf-7b79-80a9-a350-e200bda87902" class="">평균 연산(Averaging) 기반 초기화</h3><ul id="198451cf-7b79-80c4-a067-f61b2618a5f0" class="bulleted-list"><li style="list-style-type:disc">Conv Avg Init은 가중치 값을 <code>1/R²</code>로 설정하여, 기존 정보를 최대한 유지하면서 부드럽게 전환함.</li></ul><ul id="198451cf-7b79-801f-8201-cc9b59d434a1" class="bulleted-list"><li style="list-style-type:disc">즉, 단순히 압축하는 것이 아니라 기존 공간 정보를 최대한 보존하는 방식.</li></ul><p id="198451cf-7b79-8089-b96e-f0e7e4db6b4b" class="">
</p><ul id="198451cf-7b79-809e-9df2-d5344b3d375a" class="bulleted-list"><li style="list-style-type:disc">초기에는 압축 없이 학습 후, 학습이 안정화되면 KV Compression을 적용하여 연산량 감소.</li></ul><ul id="198451cf-7b79-801e-a46c-d3dc0b2471fb" class="bulleted-list"><li style="list-style-type:disc">4K 이미지 생성 시 연산량 34% 절감.</li></ul><p id="198451cf-7b79-8021-a917-e67f5a6d2ffa" class="">✅ 결과적으로, 기존 PixArt-α 대비 적은 연산량과 빠른 학습으로 4K 이미지 생성이 가능해짐.</p><figure id="198451cf-7b79-800d-b133-d38528657563" class="image"><a href="/images/2025-02-09-pixart-sigma/image%207.png"><img style="width:288px" src="/images/2025-02-09-pixart-sigma/image%207.png"/></a></figure><p id="198451cf-7b79-805c-b618-eaa6d23e9448" class="">
</p><p id="198451cf-7b79-80d2-9295-eea09dac9e2e" class="">
</p><h1 id="198451cf-7b79-800f-95c4-ffd719a9f131" class="">4. Experiment</h1><h2 id="198451cf-7b79-8032-bc3b-d4e84333d747" class="">4.1 Implementation Details (구현 세부사항)</h2><h3 id="198451cf-7b79-8096-aeb0-d3139434547a" class="">1. 모델 구성</h3><p id="198451cf-7b79-8072-8835-d3827b25682f" class="">✅ 텍스트 인코더</p><ul id="198451cf-7b79-805d-bd8f-f00a2fd2cfad" class="bulleted-list"><li style="list-style-type:disc">Flan-T5-XXL 사용 (Imagen 및 PixArt-α와 동일)</li></ul><ul id="198451cf-7b79-800b-a9f8-f30146634a3f" class="bulleted-list"><li style="list-style-type:disc">기존 모델에서 120개 토큰을 사용하던 것을 300개 토큰까지 확장하여 더 정밀한 텍스트-이미지 정렬 가능.</li></ul><p id="198451cf-7b79-80d3-bc34-cdd1e68aa78e" class="">✅ VAE (Variational Autoencoder) 적용</p><ul id="198451cf-7b79-80b9-b2f9-e517c6b66c12" class="bulleted-list"><li style="list-style-type:disc">Stable Diffusion XL(SDXL)의 VAE 사용</li></ul><ul id="198451cf-7b79-80ec-93a2-d44c0a5f18b7" class="bulleted-list"><li style="list-style-type:disc">더 높은 품질의 이미지 디코딩 가능 → 세밀한 디테일 보존</li></ul><p id="198451cf-7b79-801e-8dc7-f70530015975" class="">✅ 기반 모델</p><ul id="198451cf-7b79-8007-a03a-f46e027a826f" class="bulleted-list"><li style="list-style-type:disc">PixArt-α를 베이스 모델로 사용</li></ul><ul id="198451cf-7b79-804b-9f1b-fb525d4ab3bc" class="bulleted-list"><li style="list-style-type:disc">256px 사전 학습된 체크포인트를 활용하여 4K까지 확장</li></ul><p id="198451cf-7b79-80d7-ab1d-f28fb1bb798b" class="">✅ KV Token Compression 적용</p><ul id="198451cf-7b79-809c-981c-cb40f16c2801" class="bulleted-list"><li style="list-style-type:disc">연산량 34% 절감</li></ul><ul id="198451cf-7b79-80bd-a07d-c2eab745a372" class="bulleted-list"><li style="list-style-type:disc">초고해상도(4K) 이미지 생성을 가능하게 함</li></ul><hr id="198451cf-7b79-8009-9d3d-c828f602e868"/><h3 id="198451cf-7b79-800c-aaf2-d021f5bd42f8" class="">2. 학습 환경 및 하드웨어</h3><p id="198451cf-7b79-806a-98d7-c1396cbb93c7" class="">✅ 훈련 GPU 환경</p><ul id="198451cf-7b79-804b-bc63-de29ae3bbfa0" class="bulleted-list"><li style="list-style-type:disc">1K 모델 학습: 32 V100 GPUs 사용</li></ul><ul id="198451cf-7b79-80c4-9f40-c30bc23e7524" class="bulleted-list"><li style="list-style-type:disc">2K &amp; 4K 모델 학습: 16 A100 GPUs 사용</li></ul><p id="198451cf-7b79-80d2-9986-de3d7f458523" class="">✅ 최적화 알고리즘</p><ul id="198451cf-7b79-801d-9211-d1b80bb69d98" class="bulleted-list"><li style="list-style-type:disc">CAME Optimizer 사용 (AdamW 대신)</li></ul><ul id="198451cf-7b79-80c5-8036-e05a95837c7a" class="bulleted-list"><li style="list-style-type:disc">학습률: 2e-5 (고정 Learning Rate 사용)</li></ul><ul id="198451cf-7b79-8024-94f5-ca7e857c5f5e" class="bulleted-list"><li style="list-style-type:disc">Weight Decay: 0</li></ul><p id="198451cf-7b79-807d-a4aa-f5dafdfab886" class="">✅ Position Embedding Interpolation (PE Interp.) 적용</p><ul id="198451cf-7b79-80ad-84c6-d1bb9209125e" class="bulleted-list"><li style="list-style-type:disc">낮은 해상도에서 학습된 모델을 고해상도로 변환할 때 위치 임베딩을 보간(interpolation)하여 적용.</li></ul><ul id="198451cf-7b79-808c-9ece-f08c32f87c07" class="bulleted-list"><li style="list-style-type:disc">이를 통해 고해상도로 확장 시 성능 저하 없이 빠르게 적응 가능.</li></ul><hr id="198451cf-7b79-8064-ac3f-fd3b6b7d810a"/><h3 id="198451cf-7b79-8071-8e2f-dd8e4d0eef7e" class="">3. 학습 데이터 및 훈련 과정</h3><p id="198451cf-7b79-8048-805f-c1c9dd7b6d0f" class="">✅ 훈련 데이터셋</p><ul id="198451cf-7b79-8096-9393-e241def00a76" class="bulleted-list"><li style="list-style-type:disc">총 33M(3,300만 개)의 고해상도 이미지 사용</li></ul><ul id="198451cf-7b79-8061-ab68-ca7b598e09db" class="bulleted-list"><li style="list-style-type:disc">1K 해상도 이상의 데이터만 포함</li></ul><ul id="198451cf-7b79-8032-ba26-dffd08ac570d" class="bulleted-list"><li style="list-style-type:disc">4K 해상도 이미지 2.3M(230만 개) 포함</li></ul><ul id="198451cf-7b79-801d-b6d5-c5eca9745455" class="bulleted-list"><li style="list-style-type:disc">Aesthetic Scoring Model(AES) 적용하여 고품질 이미지 선별</li></ul><p id="198451cf-7b79-8019-a79e-efc94e58a05f" class="">✅ 훈련 과정</p><ul id="198451cf-7b79-8099-be7a-fc067f4033e9" class="bulleted-list"><li style="list-style-type:disc">256px → 512px → 1024px → 4K 해상도로 점진적 업스케일링 적용</li></ul><ul id="198451cf-7b79-8068-8f40-fb9b6240b349" class="bulleted-list"><li style="list-style-type:disc">VAE 교체 후 2K Training Steps 내 빠르게 적응</li></ul><ul id="198451cf-7b79-80c3-ae5f-c0a4c1dacc45" class="bulleted-list"><li style="list-style-type:disc">PE Interpolation을 적용하여 고해상도에서 추가 학습 비용 절감</li></ul><p id="198451cf-7b79-80e6-b2c4-e913e9e4dc26" class="">✅ 학습 비용 절감</p><ul id="198451cf-7b79-8075-ae9e-e4898949ca20" class="bulleted-list"><li style="list-style-type:disc">기존 PixArt-α 대비 훈련 비용 9%만 사용하여 1K 생성 가능</li></ul><ul id="198451cf-7b79-80d6-849a-c0deac658553" class="bulleted-list"><li style="list-style-type:disc">KV Compression과 Weak-to-Strong Training을 결합하여 GPU 비용 절감</li></ul><p id="198451cf-7b79-80b9-951b-fadb2f30e750" class="">
</p><p id="198451cf-7b79-804c-8654-e422359a61ed" class="">
</p><h2 id="198451cf-7b79-8031-8186-e079612487c8" class="">4.2 실험 결과</h2><h2 id="198451cf-7b79-8033-86bc-c5fa7d3ddf32" class="">1. 이미지 품질 비교 (Qualitative Evaluation)</h2><p id="198451cf-7b79-8019-a5e5-dd97375bd5a0" class="">PixArt-Σ는 포토리얼리즘(Photorealism), 디테일 수준, 스타일 다양성 측면에서 이전 모델보다 개선됨.</p><p id="198451cf-7b79-807a-85ee-eee09855d05a" class="">아래와 같은 모델들과 비교됨:</p><p id="198451cf-7b79-803d-9ffa-c213b7134331" class="">
</p><figure id="198451cf-7b79-80f8-a191-f350b29fb79b" class="image"><a href="/images/2025-02-09-pixart-sigma/image%208.png"><img style="width:649.984375px" src="/images/2025-02-09-pixart-sigma/image%208.png"/></a></figure><p id="198451cf-7b79-80ac-8b3a-ef886b806396" class="">
</p><p id="198451cf-7b79-80c4-a33b-e3c3c02712c2" class="">
</p><p id="198451cf-7b79-80d8-bb97-ebb9a12132bd" class="">
</p><p id="198451cf-7b79-8097-9a94-fa82db11526f" class="">
</p><p id="198451cf-7b79-8059-825b-c6da0f5e1608" class="">
</p><p id="198451cf-7b79-8048-ba4b-f63f89d79a78" class="">
</p><p id="198451cf-7b79-8021-afee-d074f3cdb3f7" class="">
</p><h2 id="198451cf-7b79-80f5-bba3-dc0e70703ea5" class="">PixArt-α vs PixArt-Σ</h2><table id="198451cf-7b79-80a1-91fc-c9ca2a989170" class="simple-table"><tbody><tr id="198451cf-7b79-80d5-8a3d-cdbb1afe4fbd"><td id="JUp^" class="">항목</td><td id="uy=K" class="">PixArt-α (기존)</td><td id="]wOL" class="" style="width:445px">PixArt-Σ (개선)</td></tr><tr id="198451cf-7b79-801c-90ce-d97324fab877"><td id="JUp^" class="">최대 해상도</td><td id="uy=K" class="">1K (1024×1024)</td><td id="]wOL" class="" style="width:445px">4K (3840×2160) 지원</td></tr><tr id="198451cf-7b79-8085-9dc3-c4f934462637"><td id="JUp^" class="">연산량 최적화</td><td id="uy=K" class="">없음</td><td id="]wOL" class="" style="width:445px">KV Token Compression 적용 (연산량 34% 감소)</td></tr><tr id="198451cf-7b79-808b-bf72-fa56cbecb820"><td id="JUp^" class="">VAE 모델</td><td id="uy=K" class="">기본 VAE</td><td id="]wOL" class="" style="width:445px">SDXL VAE로 변경 (고품질 이미지 생성 가능)</td></tr><tr id="198451cf-7b79-8084-9874-e11b7d11ea6b"><td id="JUp^" class="">학습 전략</td><td id="uy=K" class="">일반 학습</td><td id="]wOL" class="" style="width:445px">Weak-to-Strong Training (기존 모델 활용하여 빠르게 학습)</td></tr><tr id="198451cf-7b79-8072-aa76-eb1cd79052dd"><td id="JUp^" class="">텍스트 길이</td><td id="uy=K" class="">120 토큰</td><td id="]wOL" class="" style="width:445px">300 토큰으로 확장 (더 정밀한 텍스트-이미지 정렬 가능)</td></tr><tr id="198451cf-7b79-80f0-9182-ec33f1eb9196"><td id="JUp^" class="">훈련 비용</td><td id="uy=K" class="">높음</td><td id="]wOL" class="" style="width:445px">기존 대비 GPU 비용 9%로 절감</td></tr></tbody></table><p id="198451cf-7b79-8064-ae7e-cd23c918bd8a" class="">
</p><h3 id="198451cf-7b79-8058-83a4-ed7ec9583819" class="">PixArt-Σ vs. MobileDiffusion 비교표</h3><table id="198451cf-7b79-800e-a4b6-d16e8b84b775" class="simple-table"><tbody><tr id="198451cf-7b79-8001-b9f3-c1b642e098d6"><td id="VJ[n" class="">항목</td><td id="NDDF" class="">PixArt-Σ</td><td id="c|J;" class="">MobileDiffusion</td><td id="?As&gt;" class="">비교</td></tr><tr id="198451cf-7b79-8095-865a-fedcff4a52be"><td id="VJ[n" class="">목표</td><td id="NDDF" class="">4K 초고해상도 이미지 생성</td><td id="c|J;" class="">모바일에서 실시간 생성 가능하도록 최적화</td><td id="?As&gt;" class="">PixArt-Σ는 초고해상도 생성, MobileDiffusion은 On-Device 최적화</td></tr><tr id="198451cf-7b79-8030-bd88-d541063ff8e4"><td id="VJ[n" class="">모델 구조</td><td id="NDDF" class="">Diffusion Transformer (DiT) 기반</td><td id="c|J;" class="">Latent Diffusion + Optimized UNet</td><td id="?As&gt;" class="">PixArt-Σ는 Transformer 기반, MobileDiffusion은 UNet 기반</td></tr><tr id="198451cf-7b79-8083-80c5-cc9bad65f7ae"><td id="VJ[n" class="">텍스트 인코더</td><td id="NDDF" class="">Flan-T5-XXL (300 토큰까지 가능)</td><td id="c|J;" class="">CLIP-ViT/L14 (텍스트-이미지 효율성 극대화)</td><td id="?As&gt;" class="">PixArt-Σ가 더 긴 텍스트 입력 가능, MobileDiffusion은 가벼움</td></tr><tr id="198451cf-7b79-8083-837f-c2c385125a0a"><td id="VJ[n" class="">이미지 해상도</td><td id="NDDF" class="">4K (3840×2160) 직접 생성 가능</td><td id="c|J;" class="">512×512 (On-Device에서 빠르게 생성)</td><td id="?As&gt;" class="">PixArt-Σ는 초고해상도, MobileDiffusion은 저해상도 최적화</td></tr><tr id="198451cf-7b79-803d-bb02-e9287fd93d35"><td id="VJ[n" class="">KV Token Compression</td><td id="NDDF" class="">Self-Attention 연산량 34% 절감 (R=2, R=4 적용)</td><td id="c|J;" class="">❌ 사용하지 않음</td><td id="?As&gt;" class="">PixArt-Σ는 4K 최적화, MobileDiffusion은 경량 모델이라 필요 없음</td></tr><tr id="198451cf-7b79-8042-9835-d0eb7808a997"><td id="VJ[n" class="">모델 크기</td><td id="NDDF" class="">0.6B 파라미터 (SDXL: 2.6B 대비 작음)</td><td id="c|J;" class="">386M (SD-1.5 대비 55% 축소)</td><td id="?As&gt;" class="">MobileDiffusion이 더 작음</td></tr><tr id="198451cf-7b79-802e-80b0-e7547504eb6b"><td id="VJ[n" class="">VAE (Autoencoder)</td><td id="NDDF" class="">SDXL VAE 사용 (고품질 이미지 복원 가능)</td><td id="c|J;" class="">경량화된 VAE 적용 (512px에서 최적화됨)</td><td id="?As&gt;" class="">PixArt-Σ는 품질 우선, MobileDiffusion은 속도 우선</td></tr><tr id="198451cf-7b79-807d-a27c-e0c6c6d78ee5"><td id="VJ[n" class="">해상도 업스케일링 기법</td><td id="NDDF" class="">PE Interpolation (기존 모델을 고해상도로 자연스럽게 변환)</td><td id="c|J;" class="">512px 고정 (Upscaling 없음)</td><td id="?As&gt;" class="">PixArt-Σ는 해상도 확장 가능, MobileDiffusion은 저해상도 고정</td></tr><tr id="198451cf-7b79-80eb-ab58-f90c0ad23c61"><td id="VJ[n" class="">연산 최적화</td><td id="NDDF" class="">Weak-to-Strong Training (기존 모델 재사용으로 학습 비용 절감)</td><td id="c|J;" class="">Transformer 블록 제거 + Convolution 기반 최적화</td><td id="?As&gt;" class="">PixArt-Σ는 기존 모델 활용, MobileDiffusion은 경량화 모델</td></tr><tr id="198451cf-7b79-8048-a2eb-eb05e085150c"><td id="VJ[n" class="">On-Device 실행 가능 여부</td><td id="NDDF" class="">❌ 불가능 (고성능 GPU 필요)</td><td id="c|J;" class="">✅ 가능 (iPhone 15 Pro에서 0.2초 생성)</td><td id="?As&gt;" class="">MobileDiffusion이 훨씬 가벼움</td></tr><tr id="198451cf-7b79-80f1-9f3a-dcc59c45605f"><td id="VJ[n" class="">학습 데이터 크기</td><td id="NDDF" class="">33M (4K 데이터 포함, SD v1.5의 1.65%)</td><td id="c|J;" class="">150M (모바일 최적화된 데이터)</td><td id="?As&gt;" class="">MobileDiffusion이 더 큰 데이터셋 사용</td></tr><tr id="198451cf-7b79-80e3-81e4-fe4efcbf9786"><td id="VJ[n" class="">이미지 품질 평가 (FID Score)</td><td id="NDDF" class="">8.23 (PixArt-α 대비 개선됨)</td><td id="c|J;" class="">11.67 (1-step) / 8.65 (50-step DDIM)</td><td id="?As&gt;" class="">PixArt-Σ가 품질 우수, MobileDiffusion은 속도 최적화</td></tr><tr id="198451cf-7b79-80d3-ae36-e21ddc1797e0"><td id="VJ[n" class="">텍스트-이미지 정렬 (CLIP Score)</td><td id="NDDF" class="">0.2797 (PixArt-α 대비 향상됨)</td><td id="c|J;" class="">0.320 (1-step) / 0.325 (50-step DDIM)</td><td id="?As&gt;" class="">MobileDiffusion이 더 나은 정렬 성능</td></tr><tr id="198451cf-7b79-80a1-9e7c-df04d417474b"><td id="VJ[n" class="">생성 속도</td><td id="NDDF" class="">❌ 느림 (4K 생성에 고사양 GPU 필요)</td><td id="c|J;" class="">✅ 0.2초 (iPhone 15 Pro에서 실시간 생성)</td><td id="?As&gt;" class="">MobileDiffusion이 훨씬 빠름</td></tr></tbody></table><p id="199451cf-7b79-80a2-87bf-f11582cac427" class="">
</p><p id="199451cf-7b79-8008-aee9-f50ebb0f8f2e" class="">
</p><p id="199451cf-7b79-80c9-ab6a-cf2219553053" class="">
</p><p id="199451cf-7b79-8073-88ff-f336107e89e2" class="">
</p><p id="199451cf-7b79-8068-8550-e9600a5a0703" class="">
</p><p id="199451cf-7b79-80fd-8c46-ebe12d66d827" class="">
</p></div>