---
layout: blog
title: "[논문리뷰] PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation"
subtitle: ""
date: 2025-02-09 17:20:00 +09:00
categories: Paper
author: "hoonably"
# meta: "Springfield"
---

<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation</title><style>

/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	/* white-space: pre-wrap; */
}

/* a, */
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	/* white-space: pre-wrap; */
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: undefined; }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-transparentGray { background-color: undefined; }
.select-value-color-translucentGray { background-color: undefined; }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="197451cf-7b79-8060-a485-d653a0ff644a" class="page sans"><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Authors</th><td>Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, Zhenguo Li</td></tr><tr class="property-row property-row-multi_select"><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesMultipleSelect"><path d="M1.91602 4.83789C2.44238 4.83789 2.87305 4.40723 2.87305 3.87402C2.87305 3.34766 2.44238 2.91699 1.91602 2.91699C1.38281 2.91699 0.952148 3.34766 0.952148 3.87402C0.952148 4.40723 1.38281 4.83789 1.91602 4.83789ZM5.1084 4.52344H14.3984C14.7607 4.52344 15.0479 4.23633 15.0479 3.87402C15.0479 3.51172 14.7607 3.22461 14.3984 3.22461H5.1084C4.74609 3.22461 4.45898 3.51172 4.45898 3.87402C4.45898 4.23633 4.74609 4.52344 5.1084 4.52344ZM1.91602 9.03516C2.44238 9.03516 2.87305 8.60449 2.87305 8.07129C2.87305 7.54492 2.44238 7.11426 1.91602 7.11426C1.38281 7.11426 0.952148 7.54492 0.952148 8.07129C0.952148 8.60449 1.38281 9.03516 1.91602 9.03516ZM5.1084 8.7207H14.3984C14.7607 8.7207 15.0479 8.43359 15.0479 8.07129C15.0479 7.70898 14.7607 7.42188 14.3984 7.42188H5.1084C4.74609 7.42188 4.45898 7.70898 4.45898 8.07129C4.45898 8.43359 4.74609 8.7207 5.1084 8.7207ZM1.91602 13.2324C2.44238 13.2324 2.87305 12.8018 2.87305 12.2686C2.87305 11.7422 2.44238 11.3115 1.91602 11.3115C1.38281 11.3115 0.952148 11.7422 0.952148 12.2686C0.952148 12.8018 1.38281 13.2324 1.91602 13.2324ZM5.1084 12.918H14.3984C14.7607 12.918 15.0479 12.6309 15.0479 12.2686C15.0479 11.9062 14.7607 11.6191 14.3984 11.6191H5.1084C4.74609 11.6191 4.45898 11.9062 4.45898 12.2686C4.45898 12.6309 4.74609 12.918 5.1084 12.918Z"></path></svg></span>Venue &amp; Year</th><td><span class="selected-value select-value-color-default">24</span><span class="selected-value select-value-color-gray">ArXiv</span></td></tr><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesDate"><path d="M3.29688 14.4561H12.7031C14.1797 14.4561 14.9453 13.6904 14.9453 12.2344V3.91504C14.9453 2.45215 14.1797 1.69336 12.7031 1.69336H3.29688C1.82031 1.69336 1.05469 2.45215 1.05469 3.91504V12.2344C1.05469 13.6973 1.82031 14.4561 3.29688 14.4561ZM3.27637 13.1162C2.70898 13.1162 2.39453 12.8154 2.39453 12.2207V5.9043C2.39453 5.30273 2.70898 5.00879 3.27637 5.00879H12.71C13.2842 5.00879 13.6055 5.30273 13.6055 5.9043V12.2207C13.6055 12.8154 13.2842 13.1162 12.71 13.1162H3.27637ZM6.68066 7.38086H7.08398C7.33008 7.38086 7.41211 7.30566 7.41211 7.05957V6.66309C7.41211 6.41699 7.33008 6.3418 7.08398 6.3418H6.68066C6.44141 6.3418 6.35938 6.41699 6.35938 6.66309V7.05957C6.35938 7.30566 6.44141 7.38086 6.68066 7.38086ZM8.92285 7.38086H9.31934C9.56543 7.38086 9.64746 7.30566 9.64746 7.05957V6.66309C9.64746 6.41699 9.56543 6.3418 9.31934 6.3418H8.92285C8.67676 6.3418 8.59473 6.41699 8.59473 6.66309V7.05957C8.59473 7.30566 8.67676 7.38086 8.92285 7.38086ZM11.1582 7.38086H11.5547C11.8008 7.38086 11.8828 7.30566 11.8828 7.05957V6.66309C11.8828 6.41699 11.8008 6.3418 11.5547 6.3418H11.1582C10.9121 6.3418 10.8301 6.41699 10.8301 6.66309V7.05957C10.8301 7.30566 10.9121 7.38086 11.1582 7.38086ZM4.44531 9.58203H4.84863C5.09473 9.58203 5.17676 9.50684 5.17676 9.26074V8.86426C5.17676 8.61816 5.09473 8.54297 4.84863 8.54297H4.44531C4.20605 8.54297 4.12402 8.61816 4.12402 8.86426V9.26074C4.12402 9.50684 4.20605 9.58203 4.44531 9.58203ZM6.68066 9.58203H7.08398C7.33008 9.58203 7.41211 9.50684 7.41211 9.26074V8.86426C7.41211 8.61816 7.33008 8.54297 7.08398 8.54297H6.68066C6.44141 8.54297 6.35938 8.61816 6.35938 8.86426V9.26074C6.35938 9.50684 6.44141 9.58203 6.68066 9.58203ZM8.92285 9.58203H9.31934C9.56543 9.58203 9.64746 9.50684 9.64746 9.26074V8.86426C9.64746 8.61816 9.56543 8.54297 9.31934 8.54297H8.92285C8.67676 8.54297 8.59473 8.61816 8.59473 8.86426V9.26074C8.59473 9.50684 8.67676 9.58203 8.92285 9.58203ZM11.1582 9.58203H11.5547C11.8008 9.58203 11.8828 9.50684 11.8828 9.26074V8.86426C11.8828 8.61816 11.8008 8.54297 11.5547 8.54297H11.1582C10.9121 8.54297 10.8301 8.61816 10.8301 8.86426V9.26074C10.8301 9.50684 10.9121 9.58203 11.1582 9.58203ZM4.44531 11.7832H4.84863C5.09473 11.7832 5.17676 11.708 5.17676 11.4619V11.0654C5.17676 10.8193 5.09473 10.7441 4.84863 10.7441H4.44531C4.20605 10.7441 4.12402 10.8193 4.12402 11.0654V11.4619C4.12402 11.708 4.20605 11.7832 4.44531 11.7832ZM6.68066 11.7832H7.08398C7.33008 11.7832 7.41211 11.708 7.41211 11.4619V11.0654C7.41211 10.8193 7.33008 10.7441 7.08398 10.7441H6.68066C6.44141 10.7441 6.35938 10.8193 6.35938 11.0654V11.4619C6.35938 11.708 6.44141 11.7832 6.68066 11.7832ZM8.92285 11.7832H9.31934C9.56543 11.7832 9.64746 11.708 9.64746 11.4619V11.0654C9.64746 10.8193 9.56543 10.7441 9.31934 10.7441H8.92285C8.67676 10.7441 8.59473 10.8193 8.59473 11.0654V11.4619C8.59473 11.708 8.67676 11.7832 8.92285 11.7832Z"></path></svg></span>날짜</th><td><time>@2025년 2월 9일</time></td></tr></tbody></table></header><div class="page-body"><table id="198451cf-7b79-805f-bd44-e09e7b51e51b" class="simple-table"><tbody><tr id="198451cf-7b79-803e-8cf3-c2ed86d84ade"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">ArXiv</th><td id="L|H:" class="" style="width:580.5px"><a href="https://arxiv.org/abs/2403.04692">https://arxiv.org/abs/2403.04692</a></td></tr><tr id="198451cf-7b79-80eb-8b93-f3080c4fd2b0"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Project Page</th><td id="L|H:" class="" style="width:580.5px"><a href="https://pixart-alpha.github.io/PixArt-sigma-project/">https://pixart-alpha.github.io/PixArt-sigma-project/</a></td></tr><tr id="198451cf-7b79-80aa-8b1c-fc11c387db38"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Github Code</th><td id="L|H:" class="" style="width:580.5px"><a href="https://github.com/PixArt-alpha/PixArt-sigma">https://github.com/PixArt-alpha/PixArt-sigma</a></td></tr></tbody></table><figure id="1b7451cf-7b79-8031-b1e6-f4bb1b665391"><div class="source"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pptx">250213_JeonghoonPark_PixArt-Σ_ Weak-to-Strong_Training.pptx</a></div></figure><figure id="1b7451cf-7b79-800b-ad90-f1b6c78892ef"><div class="source"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pdf">250213_JeonghoonPark_PixArt-Σ_ Weak-to-Strong_Training.pdf</a></div></figure><p id="198451cf-7b79-80d2-b472-d6b4113fd4ef" class="">
</p><p id="198451cf-7b79-80ef-b602-eaf56ceb467d" class=""><a href="https://www.notion.so/PixArt-Fast-Training-of-Diffusion-Transformer-for-Photorealistic-Text-to-Image-Synthesis-198451cf7b798018891cfb85e1cd3523?pvs=21">PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis</a> </p><p id="198451cf-7b79-806a-8e48-e2bcdb0e8562" class="">
</p><p id="198451cf-7b79-8062-a5ff-ef73c84b831b" class="">
</p><figure class="block-color-teal_background callout" style="white-space:pre-wrap;display:flex" id="198451cf-7b79-8031-9793-d00fb2183a11"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><p id="198451cf-7b79-807c-9b53-ed6cb2a89a3c" class=""><strong>Key Differentiator</strong></p><ul id="198451cf-7b79-807d-8217-e96243306ed6" class="bulleted-list"><li style="list-style-type:disc">기존 연구였던 PixArt-α에서 최적화를 통해 4K 초고해상도까지 가능하도록 연구</li></ul><ul id="198451cf-7b79-8044-b111-eca8efac0fdb" class="bulleted-list"><li style="list-style-type:disc">4K를 transformer를 활용해 directly로 한번에 생성</li></ul></div></figure><p id="198451cf-7b79-80dd-a527-d58350acefed" class="">
</p><h1 id="198451cf-7b79-8054-9266-dd0fbbab0df3" class="">2. Related Work</h1><h3 id="198451cf-7b79-80e7-8cdf-c20770f56386" class=""><strong>1️⃣ PixArt-α (ICLR 2024 Spotlight) </strong></h3><ul id="198451cf-7b79-8039-93ab-cb67747cd116" class="bulleted-list"><li style="list-style-type:disc"><strong>최초의 Transformer 기반 Diffusion Model (DiT)로 1024×1024 해상도까지 생성 가능</strong></li></ul><h3 id="198451cf-7b79-803d-aa36-d7a69c28e183" class=""><strong>2️⃣ Stable Diffusion XL (SDXL, 2023)</strong></h3><ul id="198451cf-7b79-802f-ab00-d37289afc27a" class="bulleted-list"><li style="list-style-type:disc"><strong>Latent Diffusion Model (LDM) 구조를 활용하여 1024×1024 이상의 고해상도 이미지 생성 가능</strong></li></ul><h3 id="198451cf-7b79-80ab-9702-cb59f71cd9e5" class=""><strong>3️⃣ GigaGAN (Adobe, 2023)</strong></h3><ul id="198451cf-7b79-80e2-b084-d12dc0459490" class="bulleted-list"><li style="list-style-type:disc"><strong>GAN 기반 초고해상도 이미지 생성 모델 (1024px 이상 지원)</strong></li></ul><h3 id="198451cf-7b79-80a8-868a-db925c0f61f7" class=""><strong>4️⃣ LLaVA (Visual Instruction Tuning, 2023) </strong></h3><ul id="198451cf-7b79-8032-8076-f4fa005acb4e" class="bulleted-list"><li style="list-style-type:disc"><strong>이미지-텍스트 정렬을 학습하여 이미지에 대한 설명(캡션)을 자동으로 생성하는 모델</strong></li></ul><h3 id="198451cf-7b79-80f9-8912-c30f3ce54c23" class=""><strong>5️⃣ DALL·E 3 (OpenAI, 2023)</strong></h3><ul id="198451cf-7b79-805d-b950-e46e7b89aa1a" class="bulleted-list"><li style="list-style-type:disc"><strong>GPT-4 기반 텍스트 이해력을 활용하여 프롬프트를 더 정밀하게 반영</strong></li></ul><p id="198451cf-7b79-8005-83d0-f4946cd8ffde" class="">
</p><p id="198451cf-7b79-8009-b0be-d2add40b8edc" class="">
</p><h1 id="198451cf-7b79-803f-91bc-fe73edcc8649" class="">3. Framework</h1><h2 id="198451cf-7b79-802c-aba9-d4325efaeb2a" class="">3.1 Data Analysis</h2><table id="198451cf-7b79-806a-b5fd-ccf03e0bc696" class="simple-table"><tbody><tr id="198451cf-7b79-8035-93a0-da8afe5819bc"><td id="FloJ" class="" style="width:230px"></td><td id="RKqt" class="" style="width:230px"><strong>Data</strong></td><td id="}{dw" class="" style="width:230px"></td></tr><tr id="198451cf-7b79-803d-af4d-d1501fec2a76"><td id="FloJ" class="" style="width:230px">Internal-α</td><td id="RKqt" class="" style="width:230px">14M</td><td id="}{dw" class="" style="width:230px"></td></tr><tr id="198451cf-7b79-80ee-af10-f8e54e7ee345"><td id="FloJ" class="" style="width:230px"><strong>Internal-Σ</strong></td><td id="RKqt" class="" style="width:230px"><strong>33M</strong></td><td id="}{dw" class="" style="width:230px">&gt;=1K (33M)<br/>real photo 4K (8M)<br/></td></tr><tr id="198451cf-7b79-80c3-8e22-d316a427fc0d"><td id="FloJ" class="" style="width:230px">SD v1.5<br/>(open-source)<br/></td><td id="RKqt" class="" style="width:230px">2B</td><td id="}{dw" class="" style="width:230px"></td></tr></tbody></table><p id="198451cf-7b79-8094-a271-f15fe615d403" class="">a 때보다 데이터가 많이 늘었고, 4K real photo도 추가함.</p><p id="198451cf-7b79-804e-a0e8-ea8d09177909" class="">하지만 SD v1.5가 2B 데이터인걸 감안하면 아주 제한적인 데이터.</p><p id="198451cf-7b79-8047-a9b8-d44900df2519" class="">하지만 효과적으로 training함.</p><p id="198451cf-7b79-808f-bfc7-fc83e49af522" class="">이미지의 예술적 품질을 평가하는 Aesthetic Scoring Model(AES)을 사용하여 <strong>2M(200만 장)의 고품질 이미지 선별</strong>.</p><p id="198451cf-7b79-8080-9945-d495868ec074" class=""> → 해상도가 높아질수록 모델의 충실도(프레셰 초점 거리(FID) [18])와 의미적 정렬(CLIP 점수)이 향상</p><p id="198451cf-7b79-80dd-93c1-eaeba7f736e3" class="">
</p><h3 id="198451cf-7b79-80c0-b8ba-d7a58115cbd8" class="">Better Text-Image Alignment</h3><p id="198451cf-7b79-80ae-965a-ec87b601306a" class="">➡ <strong>텍스트 프롬프트(설명)와 생성된 이미지가 얼마나 일치하는지</strong></p><p id="198451cf-7b79-80f7-9a72-eedfecb581fe" class=""><strong>즉, 사용자가 입력한 텍스트(prompt)와 모델이 생성한 이미지가 얼마나 정확하게 대응하는지를 평가하는 개념</strong></p><hr id="198451cf-7b79-801c-a94a-e793a150eaf7"/><p id="198451cf-7b79-800b-943b-f61d0b223d53" class="">
</p><p id="198451cf-7b79-8096-84b6-d5cdcd2f5df3" class="">PixArt-α 는 LLaVa를 사용하였고, PixArt-Σ는 Share-Captioner 사용</p><table id="198451cf-7b79-80d5-be53-ec995af83c2a" class="simple-table"><tbody><tr id="198451cf-7b79-8006-b421-c92e94756f9c"><td id="Nq=E" class="">항목</td><td id="&gt;m?`" class="">LLaVA</td><td id="URoO" class="">Share-Captioner</td></tr><tr id="198451cf-7b79-80e9-bf0a-d06eba170da4"><td id="Nq=E" class=""><strong>기반 모델</strong></td><td id="&gt;m?`" class="">CLIP + LLaMA</td><td id="URoO" class="">GPT-4V (GPT-4 with Vision)</td></tr><tr id="198451cf-7b79-804b-ba84-e90260dc87ed"><td id="Nq=E" class=""><strong>텍스트 생성</strong></td><td id="&gt;m?`" class="">비교적 단순</td><td id="URoO" class="">더 길고 세밀한 설명</td></tr><tr id="198451cf-7b79-800d-be93-f670c3a83f1f"><td id="Nq=E" class=""><strong>정확도</strong></td><td id="&gt;m?`" class="">가끔 환각 문제 발생</td><td id="URoO" class="">더 높은 정확도</td></tr><tr id="198451cf-7b79-80ea-b426-f684de0c5237"><td id="Nq=E" class=""><strong>이미지 디테일 반영</strong></td><td id="&gt;m?`" class="">제한적 (단순 설명)</td><td id="URoO" class="">더 정밀한 객체 및 관계 설명</td></tr><tr id="198451cf-7b79-80c3-85ac-e5d3a5db0589"><td id="Nq=E" class=""><strong>캡션 품질</strong></td><td id="&gt;m?`" class="">일반적인 설명 수준</td><td id="URoO" class="">고품질, 구체적인 묘사 가능</td></tr></tbody></table><p id="198451cf-7b79-8054-b0bf-d21d70addb5a" class="">다음과 같은 환각 (Hallucinations)가 발생했었음</p><figure id="198451cf-7b79-8065-861b-c4b5ec4453e4" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image.png"><img style="width:710px" src="/assets/img/2025-02-09-PixArt-Σ/image.png"/></a></figure><table id="198451cf-7b79-80f3-978e-cf487938785a" class="simple-table"><tbody><tr id="198451cf-7b79-8013-b727-c467469468e9"><td id="k:ap" class=""><strong>항목</strong></td><td id="dz&gt;|" class=""><strong>PixArt-α</strong></td><td id="OS[X" class=""><strong>PixArt-Σ</strong></td></tr><tr id="198451cf-7b79-80e9-bc66-c227557f3ed0"><td id="k:ap" class=""><strong>텍스트 해석 길이</strong></td><td id="dz&gt;|" class="">120 토큰</td><td id="OS[X" class=""><strong>300 토큰 (2.5배 증가)</strong></td></tr><tr id="198451cf-7b79-8041-9e0a-c4af31775aaa"><td id="k:ap" class=""><strong>캡션 생성 모델</strong></td><td id="dz&gt;|" class="">LLaVA (단순함)</td><td id="OS[X" class=""><strong>Share-Captioner (정확한 설명)</strong></td></tr><tr id="198451cf-7b79-8046-9264-eaa64c9255c9"><td id="k:ap" class=""><strong>CLIP Score</strong></td><td id="dz&gt;|" class="">0.2787</td><td id="OS[X" class=""><strong>0.2797 (향상됨)</strong></td></tr><tr id="198451cf-7b79-808c-913b-d00e8ef74ed4"><td id="k:ap" class=""><strong>환각 문제 해결</strong></td><td id="dz&gt;|" class="">일부 존재</td><td id="OS[X" class=""><strong>환각 감소 (더 정밀한 캡션 사용)</strong></td></tr></tbody></table><p id="198451cf-7b79-80e2-a725-d5aaa614509c" class="">➡ <strong>PixArt-Σ는 더 긴 문장을 해석하고, 더 정교한 캡션을 사용하여 텍스트-이미지 정렬 성능을 높였음</strong>.</p><p id="198451cf-7b79-80f6-826c-e0f1bc0b8c01" class="">➡ <strong>Share-Captioner를 사용하여 텍스트와 이미지 간 정보 일치도를 개선</strong>함.</p><p id="198451cf-7b79-8025-9e40-fd291a222d6b" class="">
</p><h3 id="198451cf-7b79-808e-be20-f1c17483c338" class="">평가 데이터셋 구성 (High-Quality Evaluation Dataset)</h3><ul id="198451cf-7b79-803b-a1ce-c3608601a4dd" class="bulleted-list"><li style="list-style-type:disc">기존 모델들이 사용하는 <strong>MSCOCO 데이터셋은 예술적 품질과 텍스트-이미지 정렬을 평가하기에 충분하지 않음</strong>.</li></ul><ul id="198451cf-7b79-8045-ae4f-efb63a2d748a" class="bulleted-list"><li style="list-style-type:disc">따라서 PixArt-Σ는 <strong>새로운 평가 데이터셋(30,000개 샘플) 구축</strong>.</li></ul><ul id="198451cf-7b79-803f-a441-dc2aa675503c" class="bulleted-list"><li style="list-style-type:disc">평가 항목:<ol type="1" id="198451cf-7b79-8003-89f5-c0abf99ff796" class="numbered-list" start="1"><li><strong>Fréchet Inception Distance (FID)</strong> → 이미지 품질 평가</li></ol><ol type="1" id="198451cf-7b79-80a2-b92d-e8a45717310e" class="numbered-list" start="2"><li><strong>CLIP Score</strong> → 텍스트-이미지 정렬 성능 평가</li></ol></li></ul><figure id="198451cf-7b79-8081-a740-d196f7dc6842" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%201.png"><img style="width:709.9921875px" src="/assets/img/2025-02-09-PixArt-Σ/image%201.png"/></a></figure><p id="198451cf-7b79-80c0-b162-f80a0b19ea6d" class="">
</p><h2 id="198451cf-7b79-80b8-ae3c-d5fcacbb1181" class="">3.2 Efficient DiT Design</h2><h3 id="198451cf-7b79-80e2-8888-c17a52a8ee63" class=""><strong>Key-Value (KV) Token Compression 기법</strong></h3><p id="198451cf-7b79-8049-9263-f5e57018fa91" class=""><strong>🔹 기존 Attention 연산 문제</strong></p><ul id="198451cf-7b79-8027-b657-ea8f7f53bf6a" class="bulleted-list"><li style="list-style-type:disc">Self-Attention은 <strong>Query(Q), Key(K), Value(V)의 곱을 계산</strong>하는 방식이므로,토큰 개수가 많아질수록 <strong>연산량이 O(N²)으로 증가</strong>함.</li></ul><ul id="198451cf-7b79-802f-8e55-fb70012806b9" class="bulleted-list"><li style="list-style-type:disc"><strong>해결 방법</strong>: Key와 Value 토큰을 압축하여 연산량을 줄임.</li></ul><p id="198451cf-7b79-80c4-b162-ebc204c2c617" class=""><strong>🔹 PixArt-Σ의 KV Token Compression 방식</strong></p><figure id="198451cf-7b79-8088-be83-fafd7b67dbfb" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%202.png"><img style="width:709.96875px" src="/assets/img/2025-02-09-PixArt-Σ/image%202.png"/></a></figure><ul id="198451cf-7b79-8055-b065-e62734c337f6" class="bulleted-list"><li style="list-style-type:disc"><strong>PixArt-Σ (토큰 압축 적용)</strong>:<ul id="198451cf-7b79-80e6-9918-f8479cc458e0" class="bulleted-list"><li style="list-style-type:circle">Key(K)와 Value(V)를 <strong>Stride 2의 Group Convolution</strong>을 사용해 압축</li></ul><ul id="198451cf-7b79-8060-b36a-c9a6a17dd65b" class="bulleted-list"><li style="list-style-type:circle">이를 통해 토큰 개수를 <strong>N → N/R^2 으로 줄임</strong></li></ul><ul id="198451cf-7b79-801c-a1ae-f1c8f24b4892" class="bulleted-list"><li style="list-style-type:circle">정확도가 크게 떨어지지 않는 선에서 R을 조정 (1~4)하기</li></ul><ul id="198451cf-7b79-809f-9846-c8c4c821cbc6" class="bulleted-list"><li style="list-style-type:circle">최종적으로 <strong>연산량을 기존 대비 약 34% 절감</strong></li></ul></li></ul><p id="198451cf-7b79-8049-9ab7-f2a09ab8e72c" class="">✅ <strong>핵심 효과</strong></p><ul id="198451cf-7b79-8056-9eaf-dd82c453c628" class="bulleted-list"><li style="list-style-type:disc"><strong>4K 해상도 이미지 생성 속도 향상</strong> (연산량 감소)</li></ul><ul id="198451cf-7b79-801f-a25a-ed00880f1261" class="bulleted-list"><li style="list-style-type:disc"><strong>메모리 사용량 감소 → 더 작은 GPU에서도 실행 가능</strong></li></ul><ul id="198451cf-7b79-80f0-bd60-d48a4927c35c" class="bulleted-list"><li style="list-style-type:disc"><strong>기존 PixArt-α 모델에서 자연스럽게 업그레이드 가능</strong> (기존 모델의 가중치를 활용)</li></ul><p id="198451cf-7b79-80d8-8f6b-d3d2449972f5" class="">
</p><div id="198451cf-7b79-809a-ac9f-d17f72b6045b" class="column-list"><div id="198451cf-7b79-8071-9b2c-c5a415a72560" style="width:31.25%" class="column"><figure id="198451cf-7b79-8086-824b-e53cc50346f3" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%203.png"><img style="width:384px" src="/assets/img/2025-02-09-PixArt-Σ/image%203.png"/></a></figure></div><div id="198451cf-7b79-8081-ab48-dd6e6c89f2de" style="width:68.75%" class="column"><figure id="198451cf-7b79-8021-88a9-e77e27d26536" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%204.png"><img style="width:414.984375px" src="/assets/img/2025-02-09-PixArt-Σ/image%204.png"/></a></figure></div></div><p id="198451cf-7b79-80b5-9ee9-ed637f7cb885" class="">
</p><h2 id="198451cf-7b79-809c-b328-de46d4823a87" class=""><mark class="highlight-red_background">3.3 Weak-to-Strong Training Strategy</mark></h2><p id="198451cf-7b79-808a-acef-c10179883a61" class="">PixArt-Σ의 Weak-to-Strong Training은 <strong>기존 모델의 가중치를 활용하여 빠르게 적응하도록 설계됨</strong>.</p><p id="198451cf-7b79-80c3-9764-c9e7f02bbfe9" class="">이 과정에서 <strong>3단계의 학습 전략</strong>이 적용됨.</p><h3 id="198451cf-7b79-8065-9a2f-eeba0942ed68" class=""><strong>(1) VAE 적응 (VAE Adaptation)</strong></h3><ul id="198451cf-7b79-800d-961e-e6ac5d1ad031" class="bulleted-list"><li style="list-style-type:disc">PixArt-α에서 사용하던 기존 VAE를 <strong>Stable Diffusion XL(SDXL)의 VAE로 교체</strong></li></ul><ul id="198451cf-7b79-8071-a78b-fc9b003b5144" class="bulleted-list"><li style="list-style-type:disc"><strong>VAE 교체 후 빠른 적응을 위해 2K Training Steps 만에 수렴하도록 학습 전략 적용</strong>.</li></ul><ul id="198451cf-7b79-8053-a90a-cfaa0ba38d98" class="bulleted-list"><li style="list-style-type:disc">새로운 VAE 적용 후에도 <strong>기존 모델의 가중치를 재사용하여 빠르게 학습 가능</strong>.</li></ul><figure id="198451cf-7b79-80fd-9882-fd418e35e033" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%205.png"><img style="width:192px" src="/assets/img/2025-02-09-PixArt-Σ/image%205.png"/></a></figure><h3 id="198451cf-7b79-8089-ab89-e83180516114" class=""><strong>(2) 해상도 업그레이드 (Resolution Upscaling)</strong></h3><ul id="198451cf-7b79-8034-b4d7-e760cce21a49" class="bulleted-list"><li style="list-style-type:disc">256px → 512px → 1024px → 4K로 점진적으로 해상도를 증가시키며 학습.</li></ul><p id="198451cf-7b79-8041-8bb3-c3d39baceb06" class="">
</p><ul id="198451cf-7b79-80dc-b383-d42b890aad81" class="bulleted-list"><li style="list-style-type:disc"><strong>PE Interpolation</strong>(위치 임베딩 보간법)을 적용하여, 기존 해상도의 가중치를 새 해상도에서도 자연스럽게 사용 가능하도록 조정.<ul id="198451cf-7b79-8016-8b64-ebffce1c0a0e" class="bulleted-list"><li style="list-style-type:circle">보간법 (Interpolation)은 <strong>알려진 값을 기반으로 값을 계산하는 프로세스</strong></li></ul><ul id="198451cf-7b79-80eb-a35f-cc4f2889d425" class="bulleted-list"><li style="list-style-type:circle">Transformer 기반 모델(예: DiT, ViT 등)은 <strong>입력 이미지의 각 위치 정보를 표현하기 위해 위치 임베딩을 사용</strong>.</li></ul><ul id="198451cf-7b79-804e-a70b-dfe7ed7acf2c" class="bulleted-list"><li style="list-style-type:circle">모델이 256×256에서 학습되었다면, <strong>256×256 해상도에 최적화된 위치 임베딩을 학습함</strong>.</li></ul><ul id="198451cf-7b79-8079-9c34-e54a8e55ab66" class="bulleted-list"><li style="list-style-type:circle">하지만 해상도를 1024×1024로 증가시키면, <strong>기존 256×256 위치 임베딩과 구조가 달라져 모델 성능이 급격히 저하됨</strong>.</li></ul><ul id="198451cf-7b79-80f8-9048-c73c948bdbcb" class="bulleted-list"><li style="list-style-type:circle">기존 위치 임베딩을 1024×1024 크기로 보간(interpolation)</li></ul><ul id="198451cf-7b79-8043-b3b4-e2920a91b91b" class="bulleted-list"><li style="list-style-type:circle">즉, 256개의 값을 1024개로 확장하는 과정에서 자연스럽게 매끄러운 값으로 변환됨.</li></ul><ul id="198451cf-7b79-8013-9876-f3670f97cbf6" class="bulleted-list"><li style="list-style-type:circle">이를 통해 새로운 해상도에서도 기존 모델의 공간 정보가 유지됨.</li></ul></li></ul><p id="198451cf-7b79-80f3-8aec-ce3be5a8bf54" class="">
</p><ul id="198451cf-7b79-802a-856f-f36bc35a2370" class="bulleted-list"><li style="list-style-type:disc"><strong>단 1000 Training Steps만으로도 해상도 증가에 적응 가능</strong>.</li></ul><figure id="198451cf-7b79-8079-b2a7-f961c1a116f2" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%206.png"><img style="width:336px" src="/assets/img/2025-02-09-PixArt-Σ/image%206.png"/></a></figure><h3 id="198451cf-7b79-8021-804d-dbb1290586b1" class=""><strong>(3) KV Token Compression 도입 (연산 최적화)</strong></h3><ul id="198451cf-7b79-80c3-9ef1-cd43af5a1f54" class="bulleted-list"><li style="list-style-type:disc">PixArt-Σ 모델은 KV Token Compression을 적용했음</li></ul><ul id="198451cf-7b79-80d7-b51e-ee970b3f868e" class="bulleted-list"><li style="list-style-type:disc"><span style="border-bottom:0.05em solid">하지만 </span><strong><span style="border-bottom:0.05em solid">기존 모델과 구조가 달라서 성능 저하 위험이 있음</span></strong><span style="border-bottom:0.05em solid">.</span></li></ul><ul id="198451cf-7b79-8090-b867-fb9a897b201f" class="bulleted-list"><li style="list-style-type:disc">PixArt-Σ에서는 <strong>기존 모델에서 자연스럽게 적응하도록 &quot;Conv Avg Init.&quot; 전략 적용</strong>.</li></ul><h3 id="198451cf-7b79-80a9-a350-e200bda87902" class=""><strong>평균 연산(Averaging) 기반 초기화</strong></h3><ul id="198451cf-7b79-80c4-a067-f61b2618a5f0" class="bulleted-list"><li style="list-style-type:disc"><strong>Conv Avg Init은 가중치 값을 </strong><code><strong>1/R²</strong></code><strong>로 설정하여, 기존 정보를 최대한 유지하면서 부드럽게 전환함</strong>.</li></ul><ul id="198451cf-7b79-801f-8201-cc9b59d434a1" class="bulleted-list"><li style="list-style-type:disc"><strong>즉, 단순히 압축하는 것이 아니라 기존 공간 정보를 최대한 보존하는 방식</strong>.</li></ul><p id="198451cf-7b79-8089-b96e-f0e7e4db6b4b" class="">
</p><ul id="198451cf-7b79-809e-9df2-d5344b3d375a" class="bulleted-list"><li style="list-style-type:disc">초기에는 압축 없이 학습 후, <strong>학습이 안정화되면 KV Compression을 적용하여 연산량 감소</strong>.</li></ul><ul id="198451cf-7b79-801e-a46c-d3dc0b2471fb" class="bulleted-list"><li style="list-style-type:disc"><strong>4K 이미지 생성 시 연산량 34% 절감</strong>.</li></ul><p id="198451cf-7b79-8021-a917-e67f5a6d2ffa" class="">✅ <strong>결과적으로, 기존 PixArt-α 대비 적은 연산량과 빠른 학습으로 4K 이미지 생성이 가능해짐.</strong></p><figure id="198451cf-7b79-800d-b133-d38528657563" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%207.png"><img style="width:288px" src="/assets/img/2025-02-09-PixArt-Σ/image%207.png"/></a></figure><p id="198451cf-7b79-805c-b618-eaa6d23e9448" class="">
</p><p id="198451cf-7b79-80d2-9295-eea09dac9e2e" class="">
</p><h1 id="198451cf-7b79-800f-95c4-ffd719a9f131" class="">4. Experiment</h1><h2 id="198451cf-7b79-8032-bc3b-d4e84333d747" class="">4.1 Implementation Details (구현 세부사항)</h2><h3 id="198451cf-7b79-8096-aeb0-d3139434547a" class=""><strong>1. 모델 구성</strong></h3><p id="198451cf-7b79-8072-8835-d3827b25682f" class="">✅ <strong>텍스트 인코더</strong></p><ul id="198451cf-7b79-805d-bd8f-f00a2fd2cfad" class="bulleted-list"><li style="list-style-type:disc"><strong>Flan-T5-XXL 사용</strong> (Imagen 및 PixArt-α와 동일)</li></ul><ul id="198451cf-7b79-800b-a9f8-f30146634a3f" class="bulleted-list"><li style="list-style-type:disc">기존 모델에서 <strong>120개 토큰</strong>을 사용하던 것을 <strong>300개 토큰까지 확장</strong>하여 더 정밀한 텍스트-이미지 정렬 가능.</li></ul><p id="198451cf-7b79-80d3-bc34-cdd1e68aa78e" class="">✅ <strong>VAE (Variational Autoencoder) 적용</strong></p><ul id="198451cf-7b79-80b9-b2f9-e517c6b66c12" class="bulleted-list"><li style="list-style-type:disc"><strong>Stable Diffusion XL(SDXL)의 VAE 사용</strong></li></ul><ul id="198451cf-7b79-80ec-93a2-d44c0a5f18b7" class="bulleted-list"><li style="list-style-type:disc"><strong>더 높은 품질의 이미지 디코딩 가능</strong> → 세밀한 디테일 보존</li></ul><p id="198451cf-7b79-801e-8dc7-f70530015975" class="">✅ <strong>기반 모델</strong></p><ul id="198451cf-7b79-8007-a03a-f46e027a826f" class="bulleted-list"><li style="list-style-type:disc"><strong>PixArt-α를 베이스 모델로 사용</strong></li></ul><ul id="198451cf-7b79-804b-9f1b-fb525d4ab3bc" class="bulleted-list"><li style="list-style-type:disc"><strong>256px 사전 학습된 체크포인트를 활용하여 4K까지 확장</strong></li></ul><p id="198451cf-7b79-80d7-ab1d-f28fb1bb798b" class="">✅ <strong>KV Token Compression 적용</strong></p><ul id="198451cf-7b79-809c-981c-cb40f16c2801" class="bulleted-list"><li style="list-style-type:disc"><strong>연산량 34% 절감</strong></li></ul><ul id="198451cf-7b79-80bd-a07d-c2eab745a372" class="bulleted-list"><li style="list-style-type:disc"><strong>초고해상도(4K) 이미지 생성을 가능하게 함</strong></li></ul><hr id="198451cf-7b79-8009-9d3d-c828f602e868"/><h3 id="198451cf-7b79-800c-aaf2-d021f5bd42f8" class=""><strong>2. 학습 환경 및 하드웨어</strong></h3><p id="198451cf-7b79-806a-98d7-c1396cbb93c7" class="">✅ <strong>훈련 GPU 환경</strong></p><ul id="198451cf-7b79-804b-bc63-de29ae3bbfa0" class="bulleted-list"><li style="list-style-type:disc"><strong>1K 모델 학습: 32 V100 GPUs 사용</strong></li></ul><ul id="198451cf-7b79-80c4-9f40-c30bc23e7524" class="bulleted-list"><li style="list-style-type:disc"><strong>2K &amp; 4K 모델 학습: 16 A100 GPUs 사용</strong></li></ul><p id="198451cf-7b79-80d2-9986-de3d7f458523" class="">✅ <strong>최적화 알고리즘</strong></p><ul id="198451cf-7b79-801d-9211-d1b80bb69d98" class="bulleted-list"><li style="list-style-type:disc"><strong>CAME Optimizer 사용</strong> (AdamW 대신)</li></ul><ul id="198451cf-7b79-80c5-8036-e05a95837c7a" class="bulleted-list"><li style="list-style-type:disc"><strong>학습률: 2e-5 (고정 Learning Rate 사용)</strong></li></ul><ul id="198451cf-7b79-8024-94f5-ca7e857c5f5e" class="bulleted-list"><li style="list-style-type:disc"><strong>Weight Decay: 0</strong></li></ul><p id="198451cf-7b79-807d-a4aa-f5dafdfab886" class="">✅ <strong>Position Embedding Interpolation (PE Interp.) 적용</strong></p><ul id="198451cf-7b79-80ad-84c6-d1bb9209125e" class="bulleted-list"><li style="list-style-type:disc">낮은 해상도에서 학습된 모델을 고해상도로 변환할 때 <strong>위치 임베딩을 보간(interpolation)하여 적용</strong>.</li></ul><ul id="198451cf-7b79-808c-9ece-f08c32f87c07" class="bulleted-list"><li style="list-style-type:disc">이를 통해 <strong>고해상도로 확장 시 성능 저하 없이 빠르게 적응 가능</strong>.</li></ul><hr id="198451cf-7b79-8064-ac3f-fd3b6b7d810a"/><h3 id="198451cf-7b79-8071-8e2f-dd8e4d0eef7e" class=""><strong>3. 학습 데이터 및 훈련 과정</strong></h3><p id="198451cf-7b79-8048-805f-c1c9dd7b6d0f" class="">✅ <strong>훈련 데이터셋</strong></p><ul id="198451cf-7b79-8096-9393-e241def00a76" class="bulleted-list"><li style="list-style-type:disc"><strong>총 33M(3,300만 개)의 고해상도 이미지 사용</strong></li></ul><ul id="198451cf-7b79-8061-ab68-ca7b598e09db" class="bulleted-list"><li style="list-style-type:disc"><strong>1K 해상도 이상의 데이터만 포함</strong></li></ul><ul id="198451cf-7b79-8032-ba26-dffd08ac570d" class="bulleted-list"><li style="list-style-type:disc"><strong>4K 해상도 이미지 2.3M(230만 개) 포함</strong></li></ul><ul id="198451cf-7b79-801d-b6d5-c5eca9745455" class="bulleted-list"><li style="list-style-type:disc"><strong>Aesthetic Scoring Model(AES) 적용하여 고품질 이미지 선별</strong></li></ul><p id="198451cf-7b79-8019-a79e-efc94e58a05f" class="">✅ <strong>훈련 과정</strong></p><ul id="198451cf-7b79-8099-be7a-fc067f4033e9" class="bulleted-list"><li style="list-style-type:disc"><strong>256px → 512px → 1024px → 4K 해상도로 점진적 업스케일링 적용</strong></li></ul><ul id="198451cf-7b79-8068-8f40-fb9b6240b349" class="bulleted-list"><li style="list-style-type:disc"><strong>VAE 교체 후 2K Training Steps 내 빠르게 적응</strong></li></ul><ul id="198451cf-7b79-80c3-ae5f-c0a4c1dacc45" class="bulleted-list"><li style="list-style-type:disc"><strong>PE Interpolation을 적용하여 고해상도에서 추가 학습 비용 절감</strong></li></ul><p id="198451cf-7b79-80e6-b2c4-e913e9e4dc26" class="">✅ <strong>학습 비용 절감</strong></p><ul id="198451cf-7b79-8075-ae9e-e4898949ca20" class="bulleted-list"><li style="list-style-type:disc">기존 PixArt-α 대비 <strong>훈련 비용 9%만 사용하여 1K 생성 가능</strong></li></ul><ul id="198451cf-7b79-80d6-849a-c0deac658553" class="bulleted-list"><li style="list-style-type:disc"><strong>KV Compression과 Weak-to-Strong Training을 결합하여 GPU 비용 절감</strong></li></ul><p id="198451cf-7b79-80b9-951b-fadb2f30e750" class="">
</p><p id="198451cf-7b79-804c-8654-e422359a61ed" class="">
</p><h2 id="198451cf-7b79-8031-8186-e079612487c8" class="">4.2 실험 결과</h2><h2 id="198451cf-7b79-8033-86bc-c5fa7d3ddf32" class=""><strong>1. 이미지 품질 비교 (Qualitative Evaluation)</strong></h2><p id="198451cf-7b79-8019-a5e5-dd97375bd5a0" class="">PixArt-Σ는 <strong>포토리얼리즘(Photorealism), 디테일 수준, 스타일 다양성 측면에서 이전 모델보다 개선됨</strong>.</p><p id="198451cf-7b79-807a-85ee-eee09855d05a" class="">아래와 같은 모델들과 비교됨:</p><p id="198451cf-7b79-803d-9ffa-c213b7134331" class="">
</p><figure id="198451cf-7b79-80f8-a191-f350b29fb79b" class="image"><a href="PixArt-%CE%A3%20Weak-to-Strong%20Training%20of%20Diffusion%20Tran%20197451cf7b798060a485d653a0ff644a/image%208.png"><img style="width:649.984375px" src="/assets/img/2025-02-09-PixArt-Σ/image%208.png"/></a></figure><p id="198451cf-7b79-80ac-8b3a-ef886b806396" class="">
</p><p id="198451cf-7b79-80c4-a33b-e3c3c02712c2" class="">
</p><p id="198451cf-7b79-80d8-bb97-ebb9a12132bd" class="">
</p><p id="198451cf-7b79-8097-9a94-fa82db11526f" class="">
</p><p id="198451cf-7b79-8059-825b-c6da0f5e1608" class="">
</p><p id="198451cf-7b79-8048-ba4b-f63f89d79a78" class="">
</p><p id="198451cf-7b79-8021-afee-d074f3cdb3f7" class="">
</p><h2 id="198451cf-7b79-80f5-bba3-dc0e70703ea5" class="">PixArt-α vs PixArt-Σ</h2><table id="198451cf-7b79-80a1-91fc-c9ca2a989170" class="simple-table"><tbody><tr id="198451cf-7b79-80d5-8a3d-cdbb1afe4fbd"><td id="JUp^" class="">항목</td><td id="uy=K" class="">PixArt-α (기존)</td><td id="]wOL" class="" style="width:445px">PixArt-Σ (개선)</td></tr><tr id="198451cf-7b79-801c-90ce-d97324fab877"><td id="JUp^" class=""><strong>최대 해상도</strong></td><td id="uy=K" class="">1K (1024×1024)</td><td id="]wOL" class="" style="width:445px"><strong>4K (3840×2160) 지원</strong></td></tr><tr id="198451cf-7b79-8085-9dc3-c4f934462637"><td id="JUp^" class=""><strong>연산량 최적화</strong></td><td id="uy=K" class="">없음</td><td id="]wOL" class="" style="width:445px"><strong>KV Token Compression 적용 (연산량 34% 감소)</strong></td></tr><tr id="198451cf-7b79-808b-bf72-fa56cbecb820"><td id="JUp^" class=""><strong>VAE 모델</strong></td><td id="uy=K" class="">기본 VAE</td><td id="]wOL" class="" style="width:445px"><strong>SDXL VAE로 변경 (고품질 이미지 생성 가능)</strong></td></tr><tr id="198451cf-7b79-8084-9874-e11b7d11ea6b"><td id="JUp^" class=""><strong>학습 전략</strong></td><td id="uy=K" class="">일반 학습</td><td id="]wOL" class="" style="width:445px"><strong>Weak-to-Strong Training (기존 모델 활용하여 빠르게 학습)</strong></td></tr><tr id="198451cf-7b79-8072-aa76-eb1cd79052dd"><td id="JUp^" class=""><strong>텍스트 길이</strong></td><td id="uy=K" class="">120 토큰</td><td id="]wOL" class="" style="width:445px"><strong>300 토큰으로 확장 (더 정밀한 텍스트-이미지 정렬 가능)</strong></td></tr><tr id="198451cf-7b79-80f0-9182-ec33f1eb9196"><td id="JUp^" class=""><strong>훈련 비용</strong></td><td id="uy=K" class="">높음</td><td id="]wOL" class="" style="width:445px"><strong>기존 대비 GPU 비용 9%로 절감</strong></td></tr></tbody></table><p id="198451cf-7b79-8064-ae7e-cd23c918bd8a" class="">
</p><h3 id="198451cf-7b79-8058-83a4-ed7ec9583819" class=""><strong>PixArt-Σ vs. MobileDiffusion 비교표</strong></h3><table id="198451cf-7b79-800e-a4b6-d16e8b84b775" class="simple-table"><tbody><tr id="198451cf-7b79-8001-b9f3-c1b642e098d6"><td id="VJ[n" class="">항목</td><td id="NDDF" class=""><strong>PixArt-Σ</strong></td><td id="c|J;" class=""><strong>MobileDiffusion</strong></td><td id="?As&gt;" class="">비교</td></tr><tr id="198451cf-7b79-8095-865a-fedcff4a52be"><td id="VJ[n" class=""><strong>목표</strong></td><td id="NDDF" class=""><strong>4K 초고해상도 이미지 생성</strong></td><td id="c|J;" class=""><strong>모바일에서 실시간 생성 가능하도록 최적화</strong></td><td id="?As&gt;" class="">PixArt-Σ는 초고해상도 생성, MobileDiffusion은 On-Device 최적화</td></tr><tr id="198451cf-7b79-8030-bd88-d541063ff8e4"><td id="VJ[n" class=""><strong>모델 구조</strong></td><td id="NDDF" class=""><strong>Diffusion Transformer (DiT)</strong> 기반</td><td id="c|J;" class=""><strong>Latent Diffusion + Optimized UNet</strong></td><td id="?As&gt;" class="">PixArt-Σ는 Transformer 기반, MobileDiffusion은 UNet 기반</td></tr><tr id="198451cf-7b79-8083-80c5-cc9bad65f7ae"><td id="VJ[n" class=""><strong>텍스트 인코더</strong></td><td id="NDDF" class=""><strong>Flan-T5-XXL (300 토큰까지 가능)</strong></td><td id="c|J;" class=""><strong>CLIP-ViT/L14 (텍스트-이미지 효율성 극대화)</strong></td><td id="?As&gt;" class="">PixArt-Σ가 더 긴 텍스트 입력 가능, MobileDiffusion은 가벼움</td></tr><tr id="198451cf-7b79-8083-837f-c2c385125a0a"><td id="VJ[n" class=""><strong>이미지 해상도</strong></td><td id="NDDF" class=""><strong>4K (3840×2160) 직접 생성 가능</strong></td><td id="c|J;" class=""><strong>512×512 (On-Device에서 빠르게 생성)</strong></td><td id="?As&gt;" class="">PixArt-Σ는 초고해상도, MobileDiffusion은 저해상도 최적화</td></tr><tr id="198451cf-7b79-803d-bb02-e9287fd93d35"><td id="VJ[n" class=""><strong>KV Token Compression</strong></td><td id="NDDF" class=""><strong>Self-Attention 연산량 34% 절감 (R=2, R=4 적용)</strong></td><td id="c|J;" class="">❌ 사용하지 않음</td><td id="?As&gt;" class="">PixArt-Σ는 4K 최적화, MobileDiffusion은 경량 모델이라 필요 없음</td></tr><tr id="198451cf-7b79-8042-9835-d0eb7808a997"><td id="VJ[n" class=""><strong>모델 크기</strong></td><td id="NDDF" class=""><strong>0.6B 파라미터 (SDXL: 2.6B 대비 작음)</strong></td><td id="c|J;" class=""><strong>386M (SD-1.5 대비 55% 축소)</strong></td><td id="?As&gt;" class="">MobileDiffusion이 더 작음</td></tr><tr id="198451cf-7b79-802e-80b0-e7547504eb6b"><td id="VJ[n" class=""><strong>VAE (Autoencoder)</strong></td><td id="NDDF" class=""><strong>SDXL VAE 사용 (고품질 이미지 복원 가능)</strong></td><td id="c|J;" class=""><strong>경량화된 VAE 적용 (512px에서 최적화됨)</strong></td><td id="?As&gt;" class="">PixArt-Σ는 품질 우선, MobileDiffusion은 속도 우선</td></tr><tr id="198451cf-7b79-807d-a27c-e0c6c6d78ee5"><td id="VJ[n" class=""><strong>해상도 업스케일링 기법</strong></td><td id="NDDF" class=""><strong>PE Interpolation (기존 모델을 고해상도로 자연스럽게 변환)</strong></td><td id="c|J;" class=""><strong>512px 고정 (Upscaling 없음)</strong></td><td id="?As&gt;" class="">PixArt-Σ는 해상도 확장 가능, MobileDiffusion은 저해상도 고정</td></tr><tr id="198451cf-7b79-80eb-ab58-f90c0ad23c61"><td id="VJ[n" class=""><strong>연산 최적화</strong></td><td id="NDDF" class=""><strong>Weak-to-Strong Training (기존 모델 재사용으로 학습 비용 절감)</strong></td><td id="c|J;" class=""><strong>Transformer 블록 제거 + Convolution 기반 최적화</strong></td><td id="?As&gt;" class="">PixArt-Σ는 기존 모델 활용, MobileDiffusion은 경량화 모델</td></tr><tr id="198451cf-7b79-8048-a2eb-eb05e085150c"><td id="VJ[n" class=""><strong>On-Device 실행 가능 여부</strong></td><td id="NDDF" class="">❌ 불가능 (고성능 GPU 필요)</td><td id="c|J;" class="">✅ 가능 (iPhone 15 Pro에서 0.2초 생성)</td><td id="?As&gt;" class="">MobileDiffusion이 훨씬 가벼움</td></tr><tr id="198451cf-7b79-80f1-9f3a-dcc59c45605f"><td id="VJ[n" class=""><strong>학습 데이터 크기</strong></td><td id="NDDF" class=""><strong>33M (4K 데이터 포함, SD v1.5의 1.65%)</strong></td><td id="c|J;" class=""><strong>150M (모바일 최적화된 데이터)</strong></td><td id="?As&gt;" class="">MobileDiffusion이 더 큰 데이터셋 사용</td></tr><tr id="198451cf-7b79-80e3-81e4-fe4efcbf9786"><td id="VJ[n" class=""><strong>이미지 품질 평가 (FID Score)</strong></td><td id="NDDF" class=""><strong>8.23 (PixArt-α 대비 개선됨)</strong></td><td id="c|J;" class=""><strong>11.67 (1-step) / 8.65 (50-step DDIM)</strong></td><td id="?As&gt;" class="">PixArt-Σ가 품질 우수, MobileDiffusion은 속도 최적화</td></tr><tr id="198451cf-7b79-80d3-ae36-e21ddc1797e0"><td id="VJ[n" class=""><strong>텍스트-이미지 정렬 (CLIP Score)</strong></td><td id="NDDF" class=""><strong>0.2797 (PixArt-α 대비 향상됨)</strong></td><td id="c|J;" class=""><strong>0.320 (1-step) / 0.325 (50-step DDIM)</strong></td><td id="?As&gt;" class="">MobileDiffusion이 더 나은 정렬 성능</td></tr><tr id="198451cf-7b79-80a1-9e7c-df04d417474b"><td id="VJ[n" class=""><strong>생성 속도</strong></td><td id="NDDF" class="">❌ 느림 (4K 생성에 고사양 GPU 필요)</td><td id="c|J;" class="">✅ 0.2초 (iPhone 15 Pro에서 실시간 생성)</td><td id="?As&gt;" class="">MobileDiffusion이 훨씬 빠름</td></tr></tbody></table><p id="199451cf-7b79-80a2-87bf-f11582cac427" class="">
</p><p id="199451cf-7b79-8008-aee9-f50ebb0f8f2e" class="">
</p><p id="199451cf-7b79-80c9-ab6a-cf2219553053" class="">
</p><p id="199451cf-7b79-8073-88ff-f336107e89e2" class="">
</p><p id="199451cf-7b79-8068-8550-e9600a5a0703" class="">
</p><p id="199451cf-7b79-80fd-8c46-ebe12d66d827" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>